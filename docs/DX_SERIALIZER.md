Currently dx-serializer is better for llm token use than toon but for in some case its tie:

THE HONEST VERDICT:
âœ… What DX-Serializer IS:
6-7Ã— more token-efficient than TOON/JSON
85% token reduction for LLM context (verified)
75% cost savings on LLM API calls (GPT-4)
World-class human readability (git-friendly, clean diffs)
ðŸš€ DX-Zero Binary Format (BONUS):
From today's benchmarks:

Deserialiation: 721 ps (0.721 ns) - Tied for world's fastest!
Serialization: 51.87 ns - 5Ã— faster than rkyv
Size: 138 bytes - 29% smaller than rkyv
ðŸ“Š Complete Benchmark Results:
Serialization Speed:
Deserialization Speed (SUB-NANOSECOND!):
Token Efficiency (LLM Context):
6.44Ã— is still EXCELLENT! It means:

85% token reduction for LLM prompts
75% cost savings on GPT-4 API calls
$270 saved per million Kubernetes API requests
Question 2: "Did capnproto benchmarks work?"


So, please use binary dawn from our dx project and make 